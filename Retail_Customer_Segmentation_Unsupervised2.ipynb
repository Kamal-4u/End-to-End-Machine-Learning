{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamal-4u/End-to-End-Machine-Learning/blob/main/Retail_Customer_Segmentation_Unsupervised2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Kamalkant Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project at hand involves the analysis of a transnational dataset spanning from December 1, 2010, to September 12, 2011. This dataset pertains to a UK-based online retail company specializing in unique all-occasion gifts. Notably, a significant portion of the company's clientele consists of wholesale buyers.\n",
        "\n",
        "To tackle this data analysis task, several key libraries are employed. Pandas is used for data manipulation and aggregation, which is crucial for cleaning and organizing the dataset. Matplotlib and Seaborn are employed for data visualization, enabling the team to gain insights into customer behavior concerning the target variable. NumPy is leveraged to facilitate computationally efficient operations, streamlining the data analysis process. Lastly, Scikit-learn is utilized for building predictive models and segmenting the customer base.\n",
        "\n",
        "The primary objective of this project is to identify major customer segments within this online retail company's customer base. By scrutinizing the transactional data, the team aims to categorize customers into distinct segments, potentially based on their purchasing behaviors, frequency, or other relevant factors.\n",
        "\n",
        "In essence, this data-driven analysis aims to provide the company with a deeper understanding of its customer base. By uncovering major customer segments, the company can tailor its marketing and business strategies more effectively. For instance, they may identify high-value customers, allowing for targeted promotions or loyalty programs. Simultaneously, understanding the needs and preferences of wholesale buyers may lead to improved inventory management and supply chain optimization.\n",
        "\n",
        "This project underscores the significance of data analysis and segmentation in enhancing business operations. By harnessing the power of data and employing the aforementioned libraries, the company is poised to make informed decisions that can positively impact its bottom line and customer satisfaction."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub Link:-https://github.com/Kamal-4u/End-to-End-Machine-Learning\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A primary goal for any company and business is to understand their targeted customers. How their consumers operate and use their services. Every consumer may use a companies services differently. The problem we’re trying to solve is to define this delivery company’s consumers. To define certain behaviors and methods these consumers use the companies services for.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import ttest_1samp\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df=pd.read_csv('/content/drive/MyDrive/Projects/Online_Retail.csv')"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jlHRH4vbkpFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(df.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our dataset, there are some duplicate values present in CustomerId and Description. In this dataset, the Description and CustomerID have occurrences of 1454 and 135080."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "#Looking for the description of the dataset to get insights of the data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "\n",
        "* StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "\n",
        "* Description: Product (item) name. Nominal.\n",
        "\n",
        "* Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "\n",
        "* InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "\n",
        "* UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
        "CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "\n",
        "* Country: Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "#print the unique value\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#checking a duplicate value\n",
        "value= len(df[df.duplicated()])\n",
        "print(\"the number of duplicate value in dataset :\",value)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop the duplicate row\n",
        "df = df.drop_duplicates()\n",
        "len (df[df.duplicated()])"
      ],
      "metadata": {
        "id": "76_Wqb9x6KiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FMjnT7CX6kiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now i'm drop same invoiceNo which are presented \"C\" because \"c\" represent a cancellation\n",
        "df[\"InvoiceNo\"] = df[\"InvoiceNo\"].astype(\"str\")"
      ],
      "metadata": {
        "id": "lpE7Eldb6tiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "lKMK1Hm_7ugB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[~df['InvoiceNo'].str.contains('C')]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "bNM4yE7t8ZQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "sX0iXGoY85wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now convert Invice date columns are year, month,day,hours,minuts,second\n",
        "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
        "df[\"InvoiceDate_year\"] = df['InvoiceDate'].dt.year\n",
        "df['InvoiceDate_month'] = df['InvoiceDate'].dt.month\n",
        "df['InvoiceDate_day'] = df['InvoiceDate'].dt.day\n",
        "df['InvoiceDate_hour'] = df['InvoiceDate'].dt.hour\n",
        "df['InvoiceDate_minute'] = df['InvoiceDate'].dt.minute\n",
        "df['InvoiceDate_second'] = df['InvoiceDate'].dt.second"
      ],
      "metadata": {
        "id": "RXfnbAhi9Kz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns and data types\")\n",
        "pd.DataFrame(df.dtypes).rename(columns = {0:'dtype'})"
      ],
      "metadata": {
        "id": "tAvAwm4S-R_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "sYgOhF3L-Vlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2jxMw9eA-Ysm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There was some duplicate values so i removed those values.\n",
        "* I dropped InvoiceNo column which are starts with 'c' because 'c', it indicates a cancellation.\n",
        "*I converted invoice Data column into 'year','month','day','hour','minute','second'"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "viS-am3d8oXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Check the number of unique customer IDs\n",
        "print('The no. of customers = ', df['CustomerID'].nunique())\n",
        "# Count the number of transactions for each customer and sort them in descending order\n",
        "active_customers = df['CustomerID'].value_counts().reset_index()\n",
        "active_customers.columns = ['CustomerID', 'Count']  # Renaming columns for clarity\n",
        "\n",
        "# Display the most active customer\n",
        "most_active_customer = active_customers.iloc[0]\n",
        "\n",
        "print(\"The most active customer is CustomerID:\", most_active_customer['CustomerID'])\n",
        "print(\"Number of transactions:\", most_active_customer['Count'])\n",
        "\n",
        "# Plot the top 5 active customers\n",
        "plt.figure(figsize=(9, 8))\n",
        "plt.title('Top 5 active customers ID')\n",
        "sns.barplot(x='CustomerID', y='Count', data=active_customers.head(5))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best option for representing categorical variables is a bar chart.\n",
        "When comparing categorical variables, a bar chart is the most suitable choice."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 5 most active customers who have been making regular purchases have the following IDs: 17841, 14911, 14096, 12748, and 14606. These customers can be considered special because they are highly likely to make frequent purchases."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can identify the most active customers, and the company can then concentrate its efforts on nurturing and retaining these customers. By doing so, the frequency of repeat purchases increases, leading to an increase in revenue."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Analysis of Categorical Features\n",
        "categorical_columns = list(df.select_dtypes(['object']).columns)\n",
        "categorical_features = pd.Index(categorical_columns)\n",
        "\n",
        "# Analysis of Description Variable\n",
        "Description_df = df['Description'].value_counts().reset_index()\n",
        "Description_df.rename(columns={'index': 'Description_Name', 'Description': 'Count'}, inplace=True)\n",
        "\n",
        "# Display the first few rows of Description_df\n",
        "print(Description_df.head())\n",
        "\n",
        "# Plot the top 5 Product Names\n",
        "plt.figure(figsize=(9, 8))\n",
        "plt.title('Top 5 Product Name')\n",
        "sns.barplot(x='Description_Name', y='Count', data=Description_df[:5])\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best option for categorical variables is a bar chart. A bar chart is the ideal choice for comparing categorical variables."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHITE HANGING HEART T-LIGHT HOLDER is the highest-selling product, with approximately 2315 units sold. JUMBO BAG RED RETROSPOT is the second-highest selling product, with almost 2112 units sold."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The high counts of these top products indicate a strong demand and popularity among customers. This information can be utilized to ensure sufficient stock availability and plan targeted promotions, which, in turn, can boost product sales and increase revenue."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(9,7))\n",
        "plt.title('Bottom 5 product Name')\n",
        "sns.barplot(x='Description_Name', y='Count', data=Description_df[-5:])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart draw variables in one axis and corresponding values in another axis."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has been observed that items such as \"TINY CRYSTAL BRACELET RED,\" \"4 GOLD FLOCK CHRISTMAS BALLS,\" \"ZINC STAR T-LIGHT HOLDER,\" \"BLUE GINGHAM ROSE CUSHION COVER,\" and \"PAPER CRAFT, LITTLE BIRDIE\" have notably low counts, suggesting limited demand or popularity among customers"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Analysis of StockCode Variable\n",
        "StockCode_df = df['StockCode'].value_counts().reset_index()\n",
        "StockCode_df.rename(columns={'index': 'StockCode_Name', 'StockCode': 'Count'}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.title('Top 5 Stock Names')\n",
        "sns.barplot(x='StockCode_Name', y='Count', data=StockCode_df.head(5))  # Use head(5) to select the top 5\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For categorical variables Bar chart is best option."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StockCode-85123A is the top-selling product, and StockCode-85099B is the second-highest selling product."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing the demand for top stock codes enables data-driven decisions for procurement, production, and restocking, optimizing sales, reducing excess inventory, and enhancing customer satisfaction while improving revenue and profitability."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(9,8))\n",
        "plt.title('Bottom 5 Stock Name')\n",
        "sns.barplot(x='StockCode_Name',y='Count',data=StockCode_df[-5:])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For doing comparision on categorical variables Bar chart is best."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bottom 5 stock codes represent the least popular items, indicating limited customer demand."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights have been observed to create a positive business impact. By identifying the least popular stock codes, the company can optimize its inventory management. In turn, the company can focus on high-demand products, thereby increasing revenue."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Analysis of the 'Country' variable\n",
        "country_df = df['Country'].value_counts().reset_index()\n",
        "country_df.columns = ['Country_Name', 'Count']\n",
        "\n",
        "# Display the top 5 countries with the most customers\n",
        "top_5_countries = country_df.head(5)\n",
        "\n",
        "# Create a pie chart to visualize the top 5 countries\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.title('Top 5 Countries based on the Most Number of Customers')\n",
        "plt.pie(top_5_countries['Count'], labels=top_5_countries['Country_Name'], autopct='%1.1f%%', startangle=140)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For categorical variables, a pie chart is the best option."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has been observed that the UK has the highest number of customers, while Germany, France, and Ireland have nearly equal numbers of customers."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By identifying the countries with the highest number of customers, the company can concentrate its marketing efforts and allocate resources accordingly. This approach can lead to targeted marketing campaigns, enhanced customer engagement, and increased sales in these pivotal markets."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#Bar plot to show Top 5 Country based least Numbers of Customers\n",
        "\n",
        "plt.figure(figsize=(8,7))\n",
        "plt.title('Top 5 Country based least Numbers of  Customers')\n",
        "sns.barplot(x='Country_Name',y='Count',data=country_df[-5:])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is the best option for representing categorical variables.\n",
        "When comparing categorical variables, a bar chart is the most suitable choice.\n",
        "In this case, we are plotting the average number of customers in different countries from the bottom.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are very few customers from Saudi Arabia, and Bahrain is the second country with the lowest number of customers."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By comprehending the challenges or barriers specific to certain countries, the company can formulate tailored strategies for market entry, enabling it to surmount obstacles, allure a larger customer base, and attain business growth."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Analysis Numeric Features\n",
        "numerical_columns = list(df.select_dtypes(['int64', 'float64']).columns)\n",
        "numerical_features = pd.Index(numerical_columns)\n",
        "\n",
        "for col in numerical_features:\n",
        "    # Histogram\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    feature.hist(bins=50, ax=ax)\n",
        "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "    ax.set_title(col)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Skewness:\", feature.skew())\n",
        "    print(\"Kurtosis:\", feature.kurt())\n",
        "\n",
        "    # Dist Plot (excluding Car_ID)\n",
        "    if col != 'Car_ID':\n",
        "        fig = plt.figure(figsize=(9, 6))\n",
        "        ax = fig.gca()\n",
        "        sns.distplot(df[col])\n",
        "        ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "        ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "        ax.set_title(col)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Skewness:\", feature.skew())\n",
        "        print(\"Kurtosis:\", feature.kurt())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram is a suitable choice for visualizing the distribution of numerical data, allowing us to visualize how the data is distributed across different ranges or bins. It provides insights into the frequency or count of data points within each bin, giving a sense of the data's distribution pattern."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has been observed that some of the data are nearly normally distributed, some exhibit a positive skew, and others display a significant positive skew, while some are negatively skewed."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights help create a positive business impact:\n",
        "\n",
        "By understanding the distribution of data, it helps in making decisions and improving strategies in various business areas, such as marketing, sales, and operations.\n",
        "By detecting and addressing outliers, businesses can improve data quality, enhancing decision-making accuracy."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# plot a boxplot for the label by each numerical feature\n",
        "for col in numerical_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    df.boxplot(col)\n",
        "    ax.set_title('Label by ' + col)\n",
        "    #ax.set_ylabel(\"Churn\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots offer a succinct and informative visualization of numerical data, showcasing the distribution, spread, outliers, and skewness."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the columns do not contain outliers, but a few columns do have outliers."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "08iU89SDohLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes with the help of insight which i found from this will help to create business growth.\n",
        "* The identification of outliers in the data through boxplots can help businesses to identify and address data quality issues.\n",
        "* By detecting and addressing outliers, businesses can improve the accuracy and reliability of their data, leading to better decision-making and improved business performance."
      ],
      "metadata": {
        "id": "er8gr77dokjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation=df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to view the correlation between all the columns at once. To achieve this, I utilized a heatmap, which displays the correlations between columns in a single chart."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a positive correlation between InvoiceDate_day and InvoiceDate_month. There is a positive correlation between InvoiceDate_minute and InvoiceDate_hour. There is a positive correlation between InvoiceDate_hour and InvoiceDate_month."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "plt.figure(figsize=(15, 8))\n",
        "correlation = df.corr()\n",
        "sns.pairplot(df, kind=\"scatter\", diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot illustrates the pairwise relationships between numerical columns. It automatically detects numerical columns and generates pairplots for all possible pairs of numerical columns. My intent in using pairplot was to examine the correlations between these numerical columns."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The means of invoices across different months are consistent. The mean quantity matches a specified value, and the mean unit price is equivalent to a predetermined value. These statements highlight the uniformity and agreement in statistical measures, which can be essential for data analysis and decision-making."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The means of invoices across different months are equal.\n",
        "\n",
        "Alternative hypothesis (H1): At least one of the means of invoices across different months is different.\n",
        "\n",
        "Test Type: one-way ANOVA test."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Extract the \"InvoiceDate_Month\" column\n",
        "invoice_months = df['InvoiceDate_month']\n",
        "# Prepare the data for the one-way ANOVA test\n",
        "groups = [df[df['InvoiceDate_month'] == month]['InvoiceDate_month'] for month in invoice_months.unique()]\n",
        "# Perform the one-way ANOVA test\n",
        "f_statistic, p_value = f_oneway(*groups)\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "# Compare p-value to the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis. At least one of the means of invoices across different months is different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. The means of invoices across different months are equal.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used F- statistic.The F-statistic test is commonly used in statistical analysis, specifically in analysis of variance (ANOVA) tests. ANOVA is used to compare the means of two or more groups to determine if there are any significant differences between them. The F-statistic is the test statistic used in ANOVA to assess the variation between group means and the variation within groups."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here data is approximately normally distributed.thats why i used F-statistic test"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The mean quantity is equal to a specified value.\n",
        "\n",
        "Alternative hypothesis (H1): The mean quantity is not equal to the specified value."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Extract the \"Quantity\" column\n",
        "quantity = df['Quantity']\n",
        "# Specify the value to test against\n",
        "specified_value = 100  # For example, testing against a mean quantity of 10\n",
        "# Perform the one-sample t-test\n",
        "t_statistic, p_value = ttest_1samp(quantity, specified_value)\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "# Compare p-value to the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis. The mean quantity is significantly different from the specified value.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. The mean quantity is not significantly different from the specified value.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used t-Test as the statistical testing to obtain P-Value and found the result that Null hypothesis has been rejected and the mean quantity is significantly different from the specified value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is not normally distributed and for skewed data t test is best option."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Null hypothesis (H0): The mean unit price is equal to a specified value.\n",
        "\n",
        "Alternative hypothesis (H1): The mean unit price is not equal to the specified value."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Extract the \"UnitPrice\" column\n",
        "unit_price = df['UnitPrice']\n",
        "# Specify the value to test against\n",
        "specified_value = 110  # For example, testing against a mean unit price of 10\n",
        "# Perform the one-sample t-test\n",
        "t_statistic, p_value = ttest_1samp(unit_price, specified_value)\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "# Compare p-value to the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis. The mean unit price is significantly different from the specified value.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. The mean unit price is not significantly different from the specified value.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized a t-Test for statistical analysis, obtaining a P-Value that led to the rejection of the null hypothesis. This indicates a significant difference between the mean unit price and the specified value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our data distribution exhibits positive skewness, suggesting that the t-test is more appropriate for skewed data. Consequently, I employed a t-test to achieve more accurate results."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "missing_counts = df.isnull().sum()\n",
        "# To check missing values for a specific column, you can use df['ColumnName'].isnull().sum()\n",
        "description_missing = df['Description'].isnull().sum()\n",
        "customer_id_missing = df['CustomerID'].isnull().sum()\n",
        "# Print the missing value counts for each column\n",
        "print(\"Missing Value Counts for All Columns:\")\n",
        "print(missing_counts)\n",
        "# Print the missing value count for the 'Description' column\n",
        "print(\"Missing Value Count for 'Description' column:\", description_missing)\n",
        "# Print the missing value count for the 'CustomerID' column\n",
        "print(\"Missing Value Count for 'CustomerID' column:\", customer_id_missing)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "vo4fC0Qu5FPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "IWqhqwO06kFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "27oR3zYU6vF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I simply removed rows where missing values were present in this dataset. I removed all null and missing values for Description (1454) and CustomerID (134658)."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# plot a boxplot for the label by each numerical feature\n",
        "for col in numerical_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    df.boxplot(col)\n",
        "    ax.set_title('Label by ' + col)\n",
        "    #ax.set_ylabel(\"Churn\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I kept outliers in 'Quantity' and 'UnitPrice' as they can provide valuable insights into customer behavior, preferences, and purchasing patterns. Outliers may represent high-value transactions, bulk purchases, or unique buying behaviors that are essential to understand for effective customer segmentation. Removing outliers may lead to the loss of such valuable information."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Assuming 'df' is your DataFrame, let's create a new feature 'Day' from 'InvoiceDate'\n",
        "df['Day'] = df['InvoiceDate'].dt.day_name()\n",
        "\n",
        "# Calculate the 'TotalAmount' by multiplying 'Quantity' and 'UnitPrice'\n",
        "df['TotalAmount'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Display summary statistics for the 'TotalAmount' column\n",
        "total_amount_summary = df['TotalAmount'].describe()\n",
        "print(total_amount_summary)\n",
        "\n",
        "# Create a DataFrame to count the occurrences of each day\n",
        "day_df = df['Day'].value_counts().reset_index()\n",
        "day_df.rename(columns={'index': 'Day_Name', 'Day': 'Count'}, inplace=True)\n",
        "\n",
        "# Plot a bar chart of the day counts\n",
        "plt.figure(figsize=(11,6))\n",
        "plt.title('Day')\n",
        "sns.barplot(x='Day_Name', y='Count', data=day_df)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()  # Show the plot\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets create dataframe of InvoiceDate_month column:\n",
        "month_df=df['InvoiceDate_month'].value_counts().reset_index()\n",
        "month_df.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_df.rename(columns={'InvoiceDate_month': 'Count'}, inplace=True)\n",
        "month_df"
      ],
      "metadata": {
        "id": "mvsvAyjqHrqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create bar chart of dataframe which i created:\n",
        "plt.figure(figsize=(11,6))\n",
        "plt.title('Month')\n",
        "sns.barplot(x='Month_Name',y='Count',data=month_df)"
      ],
      "metadata": {
        "id": "0pJHfPo5Hxkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# create dataframe of InvoiceDate_hour column:\n",
        "hour_df=df['InvoiceDate_hour'].value_counts().reset_index()\n",
        "hour_df.rename(columns={'index': 'Hour_Name'}, inplace=True)\n",
        "hour_df.rename(columns={'InvoiceDate_hour': 'Count'}, inplace=True)\n",
        "hour_df"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create bar chart of dataframe which i created:\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Hour')\n",
        "sns.barplot(x='Hour_Name',y='Count',data=hour_df)"
      ],
      "metadata": {
        "id": "Yqsd2XpbH73-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create function to divide time into 3 category:\n",
        "def time_type(time):\n",
        "  if(time==6 or time==7 or time==8 or time==9 or time==10 or time==11):\n",
        "    return 'Morning'\n",
        "  elif(time==12 or time==13 or time==14 or time==15 or time==16 or time==17):\n",
        "    return 'Afternoon'\n",
        "  else:\n",
        "    return 'Evening'"
      ],
      "metadata": {
        "id": "McChlkkFH_i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time_type']=df['InvoiceDate_hour'].apply(time_type)"
      ],
      "metadata": {
        "id": "2lPgU2k_IHll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,8))\n",
        "plt.title('Time_type')\n",
        "sns.countplot(x='Time_type',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "seUcyGO0IK6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this graph we can see that in AfterNone Time most of the customers have purches the item.\n"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most customers have purchased gifts in the months of November, October, and December. Fewer customers have purchased gifts in the months of April, January, and February. From this graph, we can see that most customers make purchases in the afternoon. Moderate numbers of customers buy items in the morning, and the fewest customers make purchases in the evening."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation\n",
        "\n"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Creating RFM model\n",
        "Before applying any clustering algorithms it is always necessary to determine various quantitative factors on which the algorithm will perform segmentation. Examples of these would be features such as amount spend, activeness of the customer, their last visit, etc.\n",
        "\n",
        "RFM model which stands for Recency, Frequency, and Monetary is one of such steps in which we determine the recency - days to last visit, frequency - how actively the customer repurchases and monetary - total expenditure of the customer, for each customer. There are other steps too in which we divide each of these features accordingly and calculate a score for each customer. However, this approach doesnot require machine learning algorithms as segmentation can be done manually. Therefore we will skip the second step and directly use the rfm features and feed it to clustering algorithms.\n",
        "\n",
        "Recency = Latest Date - Last Inovice Data,\n",
        "\n",
        "Frequency = count of invoice no. of transaction(s),\n",
        "\n",
        "Monetary = Sum of Total Amount for each customer\n"
      ],
      "metadata": {
        "id": "NtcvBUaBGkSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "#Set Latest date 2011-12-10 as last invoice date was 2011-12-09. This is to calculate the number of days from recent purchase\n",
        "Latest_Date = dt.datetime(2011,12,10)\n",
        "\n",
        "#Create RFM Modelling scores for each customer\n",
        "rfm_df = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (Latest_Date - x.max()).days, 'InvoiceNo': lambda x: len(x), 'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "#Convert Invoice Date into type int\n",
        "rfm_df['InvoiceDate'] = rfm_df['InvoiceDate'].astype(int)\n",
        "\n",
        "#Rename column names to Recency, Frequency and Monetary\n",
        "rfm_df.rename(columns={'InvoiceDate': 'Recency',\n",
        "                         'InvoiceNo': 'Frequency',\n",
        "                         'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "rfm_df.reset_index().head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive Statistics (Recency)\n",
        "rfm_df.Recency.describe()"
      ],
      "metadata": {
        "id": "1C7O1VbZGyiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recency distribution plot\n",
        "x = rfm_df['Recency']\n",
        "plt.figure(figsize=(13,5))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "SobVeFzvG3tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive Statistics (Frequency)\n",
        "rfm_df.Frequency.describe()"
      ],
      "metadata": {
        "id": "GgQbhIMYG37x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequency distribution plot, taking observations which have frequency less than 1000\n",
        "x = rfm_df['Frequency']\n",
        "plt.figure(figsize=(13,5))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "mmFE0UwhG4AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive Statistics (Monetary)\n",
        "rfm_df.Monetary.describe()"
      ],
      "metadata": {
        "id": "zQ90VO8TG4ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Monateray distribution plot, taking observations which have monetary value less than 10000\n",
        "import seaborn as sns\n",
        "x = rfm_df['Monetary']\n",
        "plt.figure(figsize=(13,5))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "EeF2Ys_zHG91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle negative and zero values to avoid issues during log transformation\n",
        "def handle_neg_n_zero(num):\n",
        "    if num <= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return num\n",
        "\n",
        "# Apply handle_neg_n_zero function to Recency and Monetary columns\n",
        "rfm_df['Recency'] = [handle_neg_n_zero(x) for x in rfm_df['Recency']]\n",
        "rfm_df['Monetary'] = [handle_neg_n_zero(x) for x in rfm_df['Monetary']]\n",
        "\n",
        "# Perform Log transformation to bring data into normal or near-normal distribution\n",
        "Log_Tfd_Data = rfm_df[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis=1).round(3)\n",
        "\n",
        "# Calculate quantiles on the transformed data\n",
        "quantiles = Log_Tfd_Data.quantile(q=[0.25, 0.5, 0.75])\n",
        "quantiles = quantiles.to_dict()\n",
        "\n",
        "# Define scoring functions for R, F, and M segments on transformed data\n",
        "def RScoring(x, p, d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "def FnMScoring(x, p, d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Calculate R, F, and M segment values on the transformed data\n",
        "rfm_df['R'] = Log_Tfd_Data['Recency'].apply(RScoring, args=('Recency', quantiles,))\n",
        "rfm_df['F'] = rfm_df['Frequency'].apply(FnMScoring, args=('Frequency', quantiles,))\n",
        "rfm_df['M'] = rfm_df['Monetary'].apply(FnMScoring, args=('Monetary', quantiles,))\n",
        "\n",
        "# Calculate and add RFMGroup value column showing combined concatenated score of RFM\n",
        "rfm_df['RFMGroup'] = rfm_df['R'].map(str) + rfm_df['F'].map(str) + rfm_df['M'].map(str)\n",
        "\n",
        "# Calculate and add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_df['RFMScore'] = rfm_df[['R', 'F', 'M']].sum(axis=1)\n",
        "\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "TpL7fBqcHHJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data distribution after data normalization for Recency\n",
        "Recency_Plot = Log_Tfd_Data['Recency']\n",
        "plt.figure(figsize=(9,8))\n",
        "sns.distplot(Recency_Plot)"
      ],
      "metadata": {
        "id": "nlEbdSr6HHSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data distribution after data normalization for Frequency\n",
        "Frequency_Plot = Log_Tfd_Data.query('Frequency < 1000')['Frequency']\n",
        "plt.figure(figsize=(9,8))\n",
        "sns.distplot(Frequency_Plot)"
      ],
      "metadata": {
        "id": "qCxxoKNbHHZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data distribution after data normalization for Monetary\n",
        "Monetary_Plot = Log_Tfd_Data.query('Monetary < 10000')['Monetary']\n",
        "plt.figure(figsize=(9,8))\n",
        "sns.distplot(Monetary_Plot)"
      ],
      "metadata": {
        "id": "I04FMIbzG4IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import math\n",
        "rfm_df['Recency_log'] = rfm_df['Recency'].apply(math.log)\n",
        "rfm_df['Frequency_log'] = rfm_df['Frequency'].apply(math.log)\n",
        "rfm_df['Monetary_log'] = rfm_df['Monetary'].apply(math.log)"
      ],
      "metadata": {
        "id": "8fWgrlanHbB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some of the data are positively skewed so we need to convert into normally distributed,for that reason i used here log transformation.**"
      ],
      "metadata": {
        "id": "Y57tHH8XHs5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# lets scale on Recency and Monetary\n",
        "features_rec_mon=['Recency_log','Monetary_log']\n",
        "X_features_rec_mon=rfm_df[features_rec_mon].values\n",
        "scaler_rec_mon=preprocessing.StandardScaler()\n",
        "X_rec_mon=scaler_rec_mon.fit_transform(X_features_rec_mon)\n",
        "X=X_rec_mon"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the StandardScaler method is used to scale the data. It transforms the data so that it has a mean of 0 and a standard deviation of 1. Since there are some outliers in our dataset, standardization is robust to outliers. When outliers are present, they do not have a significant impact on the scaling process, which is why I chose to use this method."
      ],
      "metadata": {
        "id": "kktWPhAkIYOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Calculate quantiles on the transformed data\n",
        "quantiles = rfm_df[['Recency_log', 'Frequency_log', 'Monetary_log']].quantile(q=[0.25, 0.5, 0.75])\n",
        "quantiles = quantiles.to_dict()\n",
        "\n",
        "# Define scoring functions for R, F, and M segments on transformed data\n",
        "def RScoring(x, p, d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "def FnMScoring(x, p, d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Calculate R, F, and M segment values on the transformed data\n",
        "rfm_df['R'] = rfm_df['Recency_log'].apply(RScoring, args=('Recency_log', quantiles,))\n",
        "rfm_df['F'] = rfm_df['Frequency_log'].apply(FnMScoring, args=('Frequency_log', quantiles,))\n",
        "rfm_df['M'] = rfm_df['Monetary_log'].apply(FnMScoring, args=('Monetary_log', quantiles,))\n",
        "\n",
        "# Calculate and add RFMGroup value column showing combined concatenated score of RFM\n",
        "rfm_df['RFMGroup'] = rfm_df['R'].map(str) + rfm_df['F'].map(str) + rfm_df['M'].map(str)\n",
        "\n",
        "# Calculate and add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_df['RFMScore'] = rfm_df[['R', 'F', 'M']].sum(axis=1)\n",
        "\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}